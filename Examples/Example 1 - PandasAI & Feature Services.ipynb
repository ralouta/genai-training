{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1 - PandasAI & Feature Services\n",
    "\n",
    "In this example you will explore the following concepts:\n",
    "\n",
    "1. Connect to an Azure OpenAI Model (LLM), GPT-4o and run a simple test to make sure it's working correctly.\n",
    "2. Use PandasAI Agent to create a sample dataframe powered by your LLM to ask it a few questions about the dataset, and validate the responses.\n",
    "3. Taking the same approach from the previous step, connect a PandasAI Agent to an ArcGIS Online Feature Service, testing the questions and responses.\n",
    "\n",
    "Let's begin!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports libraries for TOML file parsing, data manipulation with pandas, AI integration with Azure and pandas, and geographic information systems (GIS) functionalities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import toml\n",
    "import pandas as pd\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from pandasai import Agent\n",
    "from data.sample_dataframe import dataframe\n",
    "\n",
    "from arcgis import GIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loads Azure configuration settings from a local TOML file and retrieves the first configuration set for use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "azure_config = toml.load(\"config.toml\")[\"configs\"][0]\n",
    "azure_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the connection using the configuration options and test a simple chat message.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = AzureChatOpenAI(\n",
    "    openai_api_version=azure_config[\"api_version\"],\n",
    "    azure_deployment=azure_config[\"deployment_name\"],\n",
    "    api_key=azure_config[\"api_key\"],\n",
    "    azure_endpoint=azure_config[\"api_endpoint\"],\n",
    "    model=azure_config[\"model_name\"],\n",
    "    model_name=azure_config[\"model_name\"],\n",
    "    temperature=0,\n",
    ")\n",
    "response = llm.invoke(\"hi\")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a simple Pandas dataframe using sample GDP and Happiness index data by country\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dataframe)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a PandasAI Agent using your LLM connection and your sample dataframe and begin asking questions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question1 = \"Calculate the sum of the gdp of north american countries\"\n",
    "question2 = \"What are the top five happiest countries in the world?\"\n",
    "question3 = \"...?\"\n",
    "\n",
    "agent = Agent(df, config={\"llm\": llm, \"enable_cache\": False})\n",
    "\n",
    "response = agent.chat(question1)\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to ArcGIS Online and load the wildfires feature layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gis = GIS()\n",
    "wildfires_item_id = \"d957997ccee7408287a963600a77f61f\"\n",
    "layer_id = 0\n",
    "wildfires_item = gis.content.get(wildfires_item_id)\n",
    "wildfires_feature_layer = wildfires_item.layers[layer_id]\n",
    "wildfires_feature_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query the wildfires layer for all the features and return the result as a Pandas dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wildfires_query_df = wildfires_feature_layer.query(\n",
    "    where=\"1=1\", out_fields=\"*\", return_geometry=False, as_df=True\n",
    ")\n",
    "wildfires_query_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a PandasAI Agent using this dataframe and our LLM connection.\n",
    "\n",
    "**Create your own question to ask and assign it to the final `question` variable that is commented out. Un-comment it, and run to see your results**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wildfires_agent = Agent(wildfires_query_df, config={\"llm\": llm, \"enable_cache\": False})\n",
    "\n",
    "question = \"How many wildfires are there right now?\"\n",
    "# question = \"List the fires that are 0 percent contained\"\n",
    "# question = \"<insert question here>\"\n",
    "\n",
    "response = wildfires_agent.chat(question)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
